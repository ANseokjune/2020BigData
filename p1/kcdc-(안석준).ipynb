{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exploring the TF-Hub CORD-19 Swivel Embeddings의 사본",
      "provenance": [],
      "collapsed_sections": [
        "5wFF5JFyD2Ki"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5wFF5JFyD2Ki"
      },
      "source": [
        "#### Copyright 2019 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uf6NouXxDqGk",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ORy-KvWXGXBo"
      },
      "source": [
        "# Exploring the TF-Hub CORD-19 Swivel Embeddings\n",
        "\n",
        "The CORD-19 Swivel text embedding module from TF-Hub (https://tfhub.dev/tensorflow/cord-19/swivel-128d/2)\n",
        " was built to support researchers analyzing natural languages text related to COVID-19.\n",
        "These embeddings were trained on the titles, authors, abstracts, body texts, and\n",
        "reference titles of articles in the [CORD-19 dataset](https://pages.semanticscholar.org/coronavirus-research).\n",
        "\n",
        "In this colab we will:\n",
        "- Analyze semantically similar words in the embedding space\n",
        "- Train a classifier on the SciCite dataset using the CORD-19 embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O4WKcsh8DH3H"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/cord_19_embeddings_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/hub/blob/master/examples/colab/cord_19_embeddings_keras.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI4ohf14xbtr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_VgRRf2I7tER"
      },
      "source": [
        "# Analyze the embeddings\n",
        "\n",
        "Let's start off by analyzing the embedding by calculating and plotting a correlation matrix between different terms. If the embedding learned to successfully capture the meaning of different words, the embedding vectors of semantically similar words should be close together. Let's take a look at some COVID-19 related terms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HNN_9bBKSLHU",
        "outputId": "69721631-d342-46e1-d2c1-16fc7e62692e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "# Use the inner product between two embedding vectors as the similarity measure\n",
        "def plot_correlation(labels, features):\n",
        "  corr = np.inner(features, features)\n",
        "  corr /= np.max(corr)\n",
        "  sns.heatmap(corr, xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "# Generate embeddings for some terms\n",
        "queries = [\n",
        "  # Related viruses\n",
        "  'coronavirus', 'SARS', 'MERS',\n",
        "  # Regions\n",
        "  'Italy', 'Spain', 'Europe',\n",
        "  # Symptoms\n",
        "  'cough', 'fever', 'throat'\n",
        "]\n",
        "\n",
        "module = hub.load('https://tfhub.dev/tensorflow/cord-19/swivel-128d/2')\n",
        "embeddings = module(queries)\n",
        "\n",
        "plot_correlation(queries, embeddings)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bg-PGqtm8B7K"
      },
      "source": [
        "We can see that the embedding successfully captured the meaning of the different terms. Each word is similar to the other words of its cluster (i.e. \"coronavirus\" highly correlates with \"SARS\" and \"MERS\"), while they are different from terms of other clusters (i.e. the similarity between \"SARS\" and \"Spain\" is close to 0).\n",
        "\n",
        "Now let's see how we can use these embeddings to solve a specific task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "idJ1jFmH7xMa"
      },
      "source": [
        "## SciCite: Citation Intent Classification\n",
        "\n",
        "This section shows how one can use the embedding for downstream tasks such as text classification. We'll use the [SciCite dataset](https://www.tensorflow.org/datasets/catalog/scicite) from TensorFlow Datasets to classify citation intents in academic papers. Given a sentence with a citation from an academic paper, classify whether the main intent of the citation is as background information, use of methods, or comparing results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ghc-CzT8DDaZ",
        "colab": {}
      },
      "source": [
        "builder = tfds.builder(name='scicite')\n",
        "builder.download_and_prepare()\n",
        "train_data, validation_data, test_data = builder.as_dataset(\n",
        "    split=('train', 'validation', 'test'),\n",
        "    as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "CVjyBD0ZPh4Z",
        "outputId": "a486267c-7582-46ff-dec4-c3cdcc1818c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#@title Let's take a look at a few labeled examples from the training set\n",
        "NUM_EXAMPLES =   10#@param {type:\"integer\"}\n",
        "\n",
        "TEXT_FEATURE_NAME = builder.info.supervised_keys[0]\n",
        "LABEL_NAME = builder.info.supervised_keys[1]\n",
        "\n",
        "def label2str(numeric_label):\n",
        "  m = builder.info.features[LABEL_NAME].names\n",
        "  return m[numeric_label]\n",
        "\n",
        "data = next(iter(train_data.batch(NUM_EXAMPLES)))\n",
        "\n",
        "data_table.DataTable(\n",
        "    pd.DataFrame({\n",
        "        TEXT_FEATURE_NAME: [ex.numpy().decode('utf8') for ex in data[0]],\n",
        "        LABEL_NAME: [label2str(x) for x in data[1]]\n",
        "    }),\n",
        "    include_index=False)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a6224c040fa35dcf/data_table.js\";\n\n      window.createDataTable({\n        data: [[\"The finding that BMI is closely related to TBF and PBF derived from DXA is compatible with several previous investigations in children over a wide age range and in adults (7, 13, 14, 16, 22, 24, 30, 32, 36).\",\n\"result\"],\n [\"The average magnitude of the NBR increases with increasing stimulus intensity and duration (Klingner et al., 2010; Shmuel et al., 2002), suggesting that NBR reflects neuronal inhibition required to optimise task performance, by reducing sensitivity and allocation of processing resources to the unattended or irrelevant part of the sensory field.\",\n\"background\"],\n [\"It has been reported that NF-\\u03baB activation can induce expression of Bcl-2 protein, thereby inhibit apoptosis.((33)) However, our results documented that HQH could attenuate adriamycin-induced cellular apoptosis, while NF-\\u03baB signaling was inhibited.\",\n\"result\"],\n [\", 2008; Quraan and Cheyne, 2008; Quraan and Cheyne, 2010), and for primary visual sources (Quraan and Cheyne, 2008; Quraan and Cheyne, 2010), and is likely the case for many other sources as most brain modules are organized with bilateral symmetry.\",\n\"background\"],\n [\"5B), but, interestingly, they shared conserved residues that are most notably found in the NQO1 family of eukaryotes (Chen et al., 2000; Faig et al, 2000).\",\n\"background\"],\n [\"Some investigators have noted an association of Pg antibodies with anti-CCP antibody levels, but not with RF values [14,15], whereas others found a correlation of Pg immunoglobulin G (IgG) antibodies with RF levels, but not with CCP antibody values [5,16].\",\n\"background\"],\n [\"In our previous study, it is documented that body weight, clinical signs and micronucleus appearance did not differ in Vit E+Setreated broiler chicks when compared with the control group (Sharaf et al., 2009) which is also an indication that this amalgamation can assuage the noxious effects of CY more effectively.\",\n\"background\"],\n [\"These subjects have intact cognitive function and their gait is essentially \\u2018\\u2018automatic\\u2019\\u2019 (Springer et al. 2006; Yogev et al. 2005), at least compared with the patient populations studied here.\",\n\"background\"],\n [\"Another study reported improved knee function following conventional treatment and retro-walking program in individuals with knee OA [25].\",\n\"background\"],\n [\"C. Data Analysis Transcription Speech samples were transcribed orthographically and analyzed using the computer program CLAN (MacWhinney, 1991).\",\n\"method\"]],\n        columns: [[\"string\", \"string\"], [\"string\", \"label\"]],\n        columnOptions: [],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    ",
            "text/plain": [
              "<google.colab.data_table.DataTable object>"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>string</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The finding that BMI is closely related to TBF...</td>\n",
              "      <td>result</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The average magnitude of the NBR increases wit...</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It has been reported that NF-κB activation can...</td>\n",
              "      <td>result</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>, 2008; Quraan and Cheyne, 2008; Quraan and Ch...</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5B), but, interestingly, they shared conserved...</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Some investigators have noted an association o...</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>In our previous study, it is documented that b...</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>These subjects have intact cognitive function ...</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Another study reported improved knee function ...</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>C. Data Analysis Transcription Speech samples ...</td>\n",
              "      <td>method</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "65s9UpYJ_1ct"
      },
      "source": [
        "## Training a citaton intent classifier\n",
        "\n",
        "We'll train a classifier on the [SciCite dataset](https://www.tensorflow.org/datasets/catalog/scicite) using Keras.  Let's build a model which use the CORD-19 embeddings with a classification layer on top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "yZUclu8xBYlj",
        "outputId": "2f575bc0-8c87-4607-b7ce-d001efe0d1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "#@title Hyperparameters { run: \"auto\" }\n",
        "\n",
        "EMBEDDING = 'https://tfhub.dev/tensorflow/cord-19/swivel-128d/2'  #@param {type: \"string\"}\n",
        "TRAINABLE_MODULE = False  #@param {type: \"boolean\"}\n",
        "\n",
        "hub_layer = hub.KerasLayer(EMBEDDING, input_shape=[], \n",
        "                           dtype=tf.string, trainable=TRAINABLE_MODULE)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dense_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer dense_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer_2 (KerasLayer)   (None, 128)               8913024   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 8,913,411\n",
            "Trainable params: 387\n",
            "Non-trainable params: 8,913,024\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "weZKWK-pLBll"
      },
      "source": [
        "## Train and evaluate the model\n",
        "\n",
        "Let's train and evaluate the model to see the performance on the SciCite task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cO1FWkZW2WS9",
        "outputId": "21b753cf-1260-4f88-d01d-9c13ad66c229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS =   35#@param {type: \"integer\"}\n",
        "BATCH_SIZE = 32#@param {type: \"integer\"}\n",
        "\n",
        "history = model.fit(train_data.shuffle(10000).batch(BATCH_SIZE),\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_data.batch(BATCH_SIZE),\n",
        "                    verbose=1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.9520 - accuracy: 0.6129 - val_loss: 0.8950 - val_accuracy: 0.6790\n",
            "Epoch 2/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8647 - accuracy: 0.7130 - val_loss: 0.8572 - val_accuracy: 0.7183\n",
            "Epoch 3/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8422 - accuracy: 0.7266 - val_loss: 0.8417 - val_accuracy: 0.7303\n",
            "Epoch 4/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8321 - accuracy: 0.7331 - val_loss: 0.8335 - val_accuracy: 0.7347\n",
            "Epoch 5/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8272 - accuracy: 0.7387 - val_loss: 0.8282 - val_accuracy: 0.7402\n",
            "Epoch 6/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8214 - accuracy: 0.7394 - val_loss: 0.8244 - val_accuracy: 0.7402\n",
            "Epoch 7/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8188 - accuracy: 0.7399 - val_loss: 0.8215 - val_accuracy: 0.7402\n",
            "Epoch 8/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8182 - accuracy: 0.7401 - val_loss: 0.8186 - val_accuracy: 0.7434\n",
            "Epoch 9/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8154 - accuracy: 0.7418 - val_loss: 0.8175 - val_accuracy: 0.7434\n",
            "Epoch 10/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8128 - accuracy: 0.7438 - val_loss: 0.8158 - val_accuracy: 0.7413\n",
            "Epoch 11/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8119 - accuracy: 0.7437 - val_loss: 0.8145 - val_accuracy: 0.7424\n",
            "Epoch 12/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8098 - accuracy: 0.7451 - val_loss: 0.8120 - val_accuracy: 0.7413\n",
            "Epoch 13/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.8023 - accuracy: 0.7504 - val_loss: 0.7932 - val_accuracy: 0.7642\n",
            "Epoch 14/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7788 - accuracy: 0.7840 - val_loss: 0.7836 - val_accuracy: 0.7795\n",
            "Epoch 15/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7750 - accuracy: 0.7869 - val_loss: 0.7808 - val_accuracy: 0.7828\n",
            "Epoch 16/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7680 - accuracy: 0.7928 - val_loss: 0.7776 - val_accuracy: 0.7817\n",
            "Epoch 17/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.7942 - val_loss: 0.7752 - val_accuracy: 0.7849\n",
            "Epoch 18/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7641 - accuracy: 0.7956 - val_loss: 0.7732 - val_accuracy: 0.7828\n",
            "Epoch 19/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7611 - accuracy: 0.7972 - val_loss: 0.7719 - val_accuracy: 0.7860\n",
            "Epoch 20/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7592 - accuracy: 0.7988 - val_loss: 0.7710 - val_accuracy: 0.7860\n",
            "Epoch 21/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7596 - accuracy: 0.8011 - val_loss: 0.7700 - val_accuracy: 0.7838\n",
            "Epoch 22/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7577 - accuracy: 0.8021 - val_loss: 0.7686 - val_accuracy: 0.7871\n",
            "Epoch 23/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7555 - accuracy: 0.8017 - val_loss: 0.7678 - val_accuracy: 0.7838\n",
            "Epoch 24/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7541 - accuracy: 0.8046 - val_loss: 0.7664 - val_accuracy: 0.7926\n",
            "Epoch 25/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7531 - accuracy: 0.8053 - val_loss: 0.7655 - val_accuracy: 0.7882\n",
            "Epoch 26/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7523 - accuracy: 0.8062 - val_loss: 0.7651 - val_accuracy: 0.7882\n",
            "Epoch 27/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7512 - accuracy: 0.8068 - val_loss: 0.7646 - val_accuracy: 0.7882\n",
            "Epoch 28/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7508 - accuracy: 0.8075 - val_loss: 0.7638 - val_accuracy: 0.7893\n",
            "Epoch 29/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7497 - accuracy: 0.8077 - val_loss: 0.7642 - val_accuracy: 0.7926\n",
            "Epoch 30/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7508 - accuracy: 0.8080 - val_loss: 0.7625 - val_accuracy: 0.7893\n",
            "Epoch 31/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7499 - accuracy: 0.8083 - val_loss: 0.7621 - val_accuracy: 0.7893\n",
            "Epoch 32/35\n",
            "257/257 [==============================] - 1s 3ms/step - loss: 0.7479 - accuracy: 0.8108 - val_loss: 0.7618 - val_accuracy: 0.7926\n",
            "Epoch 33/35\n",
            "257/257 [==============================] - 1s 4ms/step - loss: 0.7472 - accuracy: 0.8102 - val_loss: 0.7607 - val_accuracy: 0.7915\n",
            "Epoch 34/35\n",
            "257/257 [==============================] - 1s 4ms/step - loss: 0.7484 - accuracy: 0.8117 - val_loss: 0.7600 - val_accuracy: 0.7937\n",
            "Epoch 35/35\n",
            "257/257 [==============================] - 1s 4ms/step - loss: 0.7471 - accuracy: 0.8108 - val_loss: 0.7604 - val_accuracy: 0.7926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2sKE7kEyLJQZ",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  if subplot%10==1: # set up the subplots on the first call\n",
        "    plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n",
        "    plt.tight_layout()\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.set_facecolor('#F8F8F8')\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['train', 'valid.'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nnQfxevhLKld",
        "colab": {}
      },
      "source": [
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BjvtOw72Lpyw"
      },
      "source": [
        "## Evaluate the model\n",
        "\n",
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y0ExC8D0LX8m",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print('%s: %.3f' % (name, value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dWp5OWeTL2EW"
      },
      "source": [
        "We can see that the loss quickly decreases while especially the accuracy rapidly increases. Let's plot some examples to check how the prediction relates to the true labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VzHzAOaaOVC0",
        "colab": {}
      },
      "source": [
        "prediction_dataset = next(iter(test_data.batch(20)))\n",
        "\n",
        "prediction_texts = [ex.numpy().decode('utf8') for ex in prediction_dataset[0]]\n",
        "prediction_labels = [label2str(x) for x in prediction_dataset[1]]\n",
        "\n",
        "predictions = [label2str(x) for x in model.predict_classes(prediction_texts)]\n",
        "\n",
        "data_table.DataTable(\n",
        "    pd.DataFrame({\n",
        "        TEXT_FEATURE_NAME: prediction_texts,\n",
        "        LABEL_NAME: prediction_labels,\n",
        "        'prediction': predictions\n",
        "    }),\n",
        "    include_index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OSGcrkE069_Q"
      },
      "source": [
        "We can see that for this random sample, the model predicts the correct label most of the times, indicating that it can embed scientific sentences pretty well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oLE0kCfO5CIA"
      },
      "source": [
        "# What's next?\n",
        "\n",
        "Now that you've gotten to know a bit more about the CORD-19 Swivel embeddings from TF-Hub, we encourage you to participate in the CORD-19 Kaggle competition to contribute to gaining scientific insights from COVID-19 related academic texts.\n",
        "\n",
        "* Participate in the [CORD-19 Kaggle Challenge](https://www.kaggle.com/allen-institute-for-ai/CORD-19-research-challenge)\n",
        "* Learn more about the [COVID-19 Open Research Dataset (CORD-19)](https://pages.semanticscholar.org/coronavirus-research)\n",
        "* See documentation and more about the TF-Hub embeddings at https://tfhub.dev/tensorflow/cord-19/swivel-128d/2\n",
        "* Explore the CORD-19 embedding space with the [TensorFlow Embedding Projector](http://projector.tensorflow.org/?config=https://storage.googleapis.com/tfhub-examples/tensorflow/cord-19/swivel-128d/1/tensorboard/full_projector_config.json)"
      ]
    }
  ]
}